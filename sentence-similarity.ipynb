{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ff8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ac57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17d5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"Standing on one's head at job interviews forms a lasting impression.\",\n",
    "    \"It took him a month to finish the meal.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36aff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/heptagon/Desktop/sentence-similarity/data/information.csv')\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96cb7a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557f8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35328e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if file_extension.endswith(\".csv\"):   # load csv file & convert to dataframe\n",
    "#     df = pd.read_csv(filepath)\n",
    "\n",
    "# if file_extension.endswith(\".xlsx\"):    # load excel file & convert to dataframe\n",
    "#     df = pd.read_excel(filepath)\n",
    "\n",
    "# if file_extension.endswith(\".txt\"):    # load text file into dataframe\n",
    "#     df = pd.read_csv(filepath, sep=',', header=None)\n",
    "    \n",
    "# if file_extension.endswith(\".json\"):   # open json file\n",
    "#     with open(filepath,'r') as file:\n",
    "#         data = json.load(file)\n",
    "#     df = pd.DataFrame(data)    # loading into a DataFrame\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a83ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ea1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = []\n",
    "# for key_str in tqdm(df.Occupation):\n",
    "#     sentences.append(key_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd6edb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2c3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "# initialize dictionary that will contain tokenized sentences\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    # tokenize sentence and append to dictionary lists\n",
    "    new_tokens = tokenizer.encode_plus(sentence,\n",
    "                                       max_length=128,\n",
    "                                       truncation=True,\n",
    "                                       padding='max_length',\n",
    "                                       return_tensors='pt'\n",
    "                                      )\n",
    "    \n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c0d27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a10d3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf3ffd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.9229e-02,  6.2300e-01,  3.5371e-02,  ...,  8.0334e-01,\n",
       "           1.6314e+00,  3.2812e-01],\n",
       "         [ 3.6730e-02,  6.8419e-01,  1.9460e-01,  ...,  8.4759e-02,\n",
       "           1.4747e+00, -3.0080e-01],\n",
       "         [-1.2142e-02,  6.5431e-01, -7.2717e-02,  ..., -3.2600e-02,\n",
       "           1.7717e+00, -6.8121e-01],\n",
       "         ...,\n",
       "         [ 1.9532e-01,  1.1085e+00,  3.3905e-01,  ...,  1.2826e+00,\n",
       "           1.0114e+00, -7.2754e-02],\n",
       "         [ 9.0217e-02,  1.0288e+00,  3.2973e-01,  ...,  1.2940e+00,\n",
       "           9.8650e-01, -1.1125e-01],\n",
       "         [ 1.2404e-01,  9.7365e-01,  3.9329e-01,  ...,  1.1359e+00,\n",
       "           8.7685e-01, -1.0435e-01]],\n",
       "\n",
       "        [[-3.2124e-01,  8.2512e-01,  1.0554e+00,  ..., -1.8555e-01,\n",
       "           1.5169e-01,  3.9366e-01],\n",
       "         [-7.1457e-01,  1.0297e+00,  1.1217e+00,  ...,  3.3118e-02,\n",
       "           2.3820e-01, -1.5632e-01],\n",
       "         [-2.3522e-01,  1.1353e+00,  8.5941e-01,  ..., -4.3096e-01,\n",
       "          -2.7242e-02, -2.9677e-01],\n",
       "         ...,\n",
       "         [-5.4000e-01,  3.2364e-01,  7.8392e-01,  ...,  2.1870e-03,\n",
       "          -2.9941e-01,  2.6594e-01],\n",
       "         [-5.6429e-01,  3.1867e-01,  9.5759e-01,  ...,  3.4249e-02,\n",
       "          -3.0299e-01,  1.8783e-01],\n",
       "         [-5.1719e-01,  3.5987e-01,  9.3357e-01,  ...,  2.4326e-02,\n",
       "          -2.2319e-01,  1.6717e-01]],\n",
       "\n",
       "        [[-7.5756e-01,  8.3988e-01, -3.7922e-01,  ...,  1.2708e-01,\n",
       "           1.2514e+00,  1.3652e-01],\n",
       "         [-6.5908e-01,  7.6135e-01, -4.6619e-01,  ...,  2.2593e-01,\n",
       "           1.1289e+00, -3.6105e-01],\n",
       "         [-9.0070e-01,  6.7913e-01, -3.7775e-01,  ...,  1.1418e-01,\n",
       "           9.0801e-01, -1.8305e-01],\n",
       "         ...,\n",
       "         [-2.1578e-01,  5.4630e-01,  3.1171e-01,  ...,  1.8021e-01,\n",
       "           7.1693e-01, -6.7159e-02],\n",
       "         [-3.0920e-01,  4.8334e-01,  3.0211e-01,  ...,  2.2885e-01,\n",
       "           6.6559e-01, -9.3169e-02],\n",
       "         [-2.9401e-01,  4.6784e-01,  3.0949e-01,  ...,  2.7821e-01,\n",
       "           5.1436e-01, -1.0211e-01]],\n",
       "\n",
       "        [[-1.0246e-01,  9.7842e-01,  1.4798e+00,  ..., -6.7322e-01,\n",
       "          -1.3459e+00, -1.5414e-01],\n",
       "         [ 1.6459e-01,  1.1261e+00,  9.7448e-01,  ..., -8.2403e-01,\n",
       "          -1.5562e+00, -6.0396e-01],\n",
       "         [ 4.7917e-01,  9.7228e-01,  1.3746e+00,  ..., -9.8250e-01,\n",
       "          -1.3523e+00, -5.8834e-01],\n",
       "         ...,\n",
       "         [ 6.3124e-02,  3.3896e-01,  1.2718e+00,  ..., -3.9970e-01,\n",
       "          -1.1031e+00, -1.3408e-01],\n",
       "         [ 1.3678e-01,  4.4807e-01,  1.2677e+00,  ..., -3.7586e-01,\n",
       "          -1.0867e+00, -2.6921e-01],\n",
       "         [ 1.4712e-01,  3.7091e-01,  1.2411e+00,  ..., -3.6103e-01,\n",
       "          -1.1337e+00, -2.6628e-01]],\n",
       "\n",
       "        [[-6.9433e-02,  1.3936e-01,  7.9762e-01,  ...,  1.1904e-01,\n",
       "           9.8823e-01,  2.6582e-01],\n",
       "         [ 5.1375e-03, -5.3535e-02,  8.8652e-01,  ..., -2.0870e-01,\n",
       "           7.9596e-01,  2.9188e-02],\n",
       "         [-1.5181e-01,  1.4075e-02,  7.6035e-01,  ..., -2.6414e-01,\n",
       "           6.3991e-01, -1.5048e-01],\n",
       "         ...,\n",
       "         [-1.6339e-01, -5.6690e-02,  7.4140e-01,  ...,  2.4665e-01,\n",
       "           7.6735e-01,  7.6984e-02],\n",
       "         [-2.2222e-01,  1.7150e-03,  7.0698e-01,  ...,  2.1065e-01,\n",
       "           7.1550e-01,  7.8734e-02],\n",
       "         [-1.9339e-01,  2.5327e-02,  7.8219e-01,  ...,  1.7633e-01,\n",
       "           6.4733e-01,  5.0552e-02]],\n",
       "\n",
       "        [[-2.3620e-01,  8.5513e-01, -8.0395e-01,  ...,  6.1217e-01,\n",
       "           3.0030e-01, -1.4919e-01],\n",
       "         [-8.6806e-02,  9.5311e-01, -6.4188e-01,  ...,  7.8669e-01,\n",
       "           2.9603e-01, -7.3501e-01],\n",
       "         [-3.0156e-01,  1.0148e+00, -3.3798e-01,  ...,  8.6336e-01,\n",
       "           4.6252e-02, -3.6234e-01],\n",
       "         ...,\n",
       "         [-1.0904e-01,  6.3199e-01, -8.4330e-01,  ...,  7.4846e-01,\n",
       "           1.0252e-01,  1.4870e-02],\n",
       "         [ 7.2192e-03,  7.3466e-01, -7.6890e-01,  ...,  6.0643e-01,\n",
       "           1.2874e-01,  3.3143e-02],\n",
       "         [-1.1083e-01,  7.6055e-01, -4.4468e-01,  ...,  6.7188e-01,\n",
       "           1.0593e-01, -3.4437e-03]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41fa68ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ae8df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44b14933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f583c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05fc23f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec0267b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08320114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0745,  0.8637,  0.1795,  ...,  0.7734,  1.7247, -0.1803],\n",
       "        [-0.3715,  0.9729,  1.0840,  ..., -0.2552, -0.2759,  0.0358],\n",
       "        [-0.5030,  0.7950, -0.1240,  ...,  0.1441,  0.9704, -0.1791],\n",
       "        [-0.0132,  0.9773,  1.4516,  ..., -0.8462, -1.4004, -0.4118],\n",
       "        [-0.2019,  0.0597,  0.8603,  ..., -0.0100,  0.8431, -0.0841],\n",
       "        [-0.2131,  1.0175, -0.8833,  ...,  0.7371,  0.1947, -0.3011]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed / summed_mask\n",
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96165f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from PyTorch tensor to numpy array\n",
    "mean_pooled = mean_pooled.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc9e60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0744615 ,  0.86369663,  0.17946403, ...,  0.77344006,\n",
       "         1.7247488 , -0.18027496],\n",
       "       [-0.37146333,  0.9729013 ,  1.0839937 , ..., -0.25521275,\n",
       "        -0.2759373 ,  0.03575867],\n",
       "       [-0.50298226,  0.794986  , -0.12402522, ...,  0.14406362,\n",
       "         0.97037494, -0.17911562],\n",
       "       [-0.01324306,  0.9772857 ,  1.451594  , ..., -0.846165  ,\n",
       "        -1.4004318 , -0.41184372],\n",
       "       [-0.20192645,  0.05970357,  0.8602745 , ..., -0.01000803,\n",
       "         0.84306246, -0.0840771 ],\n",
       "       [-0.21311913,  1.0174934 , -0.8832755 , ...,  0.73710376,\n",
       "         0.19469155, -0.30111268]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cae6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate cosine_similarity\n",
    "# cosine_similarity(\n",
    "#     [mean_pooled[0]],\n",
    "#     mean_pooled[1:]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c51db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.33088908 0.72192585 0.17475504 0.44709677 0.5548364 ]\n",
      " [0.33088908 0.99999964 0.24826953 0.2923194  0.20174855 0.2950728 ]\n",
      " [0.72192585 0.24826953 1.         0.25110355 0.5565801  0.41768277]\n",
      " [0.17475504 0.2923194  0.25110355 0.99999994 0.26012164 0.13192454]\n",
      " [0.44709677 0.20174855 0.5565801  0.26012164 1.0000002  0.22627155]\n",
      " [0.5548364  0.2950728  0.41768277 0.13192454 0.22627155 0.9999998 ]]\n",
      "CPU times: user 2.22 ms, sys: 333 µs, total: 2.55 ms\n",
      "Wall time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = cosine_similarity(mean_pooled,mean_pooled)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e67cb849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 2],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4],\n",
       "       [5, 5]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# while True:\n",
    "rows=np.argwhere(result>.6)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32ffc7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 2], 1: [1], 2: [0, 2], 3: [3], 4: [4], 5: [5]}\n"
     ]
    }
   ],
   "source": [
    "temp_dict = {}\n",
    "for i in rows:\n",
    "    if i[0] not in temp_dict.keys():\n",
    "        temp_dict[i[0]] = []    \n",
    "        \n",
    "    if i[0] == i[1]:\n",
    "        temp_dict[i[0]].append(i[0])\n",
    "        continue\n",
    "    temp_dict[i[0]].append(i[1])\n",
    "    \n",
    "print(temp_dict)  \n",
    "\n",
    "# if temp_dict[i[0]] in temp_dict.values():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6634b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32240791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e72d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a0c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fefc51b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['Three years later, the coffin was still full of Jello.', 'The person box was packed with jelly many dozens of months later.', 'He found a leprechaun in his walnut shell.'], 1: ['The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.'], 2: ['Three years later, the coffin was still full of Jello.', 'The person box was packed with jelly many dozens of months later.', 'It took him a month to finish the meal.'], 3: [\"Standing on one's head at job interviews forms a lasting impression.\"], 4: ['The person box was packed with jelly many dozens of months later.', 'It took him a month to finish the meal.'], 5: ['Three years later, the coffin was still full of Jello.', 'He found a leprechaun in his walnut shell.']}\n"
     ]
    }
   ],
   "source": [
    "temp_dict = {}\n",
    "for i in rows:\n",
    "    if i[0] not in temp_dict.keys():\n",
    "        temp_dict[i[0]] = []    \n",
    "    if i[0] == i[1]:\n",
    "        temp_dict[i[0]].append(sentences[i[0]])\n",
    "        continue\n",
    "    temp_dict[i[0]].append(sentences[i[1]])\n",
    "print(temp_dict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f325b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c196d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b091ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c22ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d48ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39fb46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "891a0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy import spatial\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "\n",
    "# def get_embeddings(filename):\n",
    "#     with open(filename) as csv_file:\n",
    "#         # read the csv file\n",
    "#         csv_reader = csv.reader(csv_file)\n",
    "\n",
    "#     # now we can use this csv files into the pandas\n",
    "#     df = pd.DataFrame([csv_reader], index=None)\n",
    "\n",
    "#     df_embedding = df.assign(embeddings=df['Lyric'].apply(\n",
    "#         lambda x: model.encode(str(x))))\n",
    "#     print(df_embedding)\n",
    "#     return df_embedding\n",
    "\n",
    "\n",
    "# def get_similarity_score(inp, filename):\n",
    "#     data = get_embeddings(filename)\n",
    "#     inp_vector = model.encode(inp)\n",
    "#     s = data['embeddings'].apply(\n",
    "#         lambda x: 1 - spatial.distance.cosine(x, inp_vector))\n",
    "#     data = data.assign(similarity=s)\n",
    "#     return (data.sort_values('similarity', ascending=False))\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     filename = 'lyrics.csv'     # csv file name\n",
    "\n",
    "#     print(get_similarity_score('thinking about you', filename))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
